{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth First Search and Strongly Connected Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're using Datahub:\n",
    "* Run the cell below **and restart the kernel if needed**\n",
    "\n",
    "### If you're running locally:\n",
    "You'll need to perform some extra setup.\n",
    "#### First-time setup\n",
    "* Install Anaconda following the instructions here: https://www.anaconda.com/products/distribution \n",
    "* Create a conda environment: `conda create -n cs170 python=3.8`\n",
    "* Activate the environment: `conda activate cs170`\n",
    "    * See for more details on creating conda environments https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\n",
    "* Install pip: `conda install pip`\n",
    "* Install jupyter: `conda install jupyter`\n",
    "\n",
    "#### Every time you want to work\n",
    "* Make sure you've activated the conda environment: `conda activate cs170`\n",
    "* Launch jupyter: `jupyter notebook` or `jupyter lab` \n",
    "* Run the cell below **and restart the kernel if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import otter\n",
    "assert (\n",
    "    otter.__version__ >= \"4.4.1\"\n",
    "), \"Please reinstall the requirements and restart your kernel.\"\n",
    "import networkx as nx\n",
    "import typing\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "grader = otter.Notebook(\"dfs-scc.ipynb\")\n",
    "\n",
    "rng_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test cases\n",
    "file_path = \"generated_testcases.pkl\"\n",
    "\n",
    "# Load the variables from the pickle file\n",
    "with open(file_path, \"rb\") as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "file.close()\n",
    "inputs, outputs = loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representing graphs in code\n",
    "\n",
    "There are multiple ways to represent graphs in code. In class we covered [adjacency matrices](https://people.eecs.berkeley.edu/~vazirani/algorithms/chap3.pdf#page=2) and [adjacency lists](https://people.eecs.berkeley.edu/~vazirani/algorithms/chap3.pdf#page=3). There is also the edge list representation, in which you store the edges in a single 1 dimensional list. In general for CS170 and in most cases, we choose to use the adjacency list representation since it allows us to efficiently search over a node's neighbors.\n",
    "\n",
    "In many programming problems, verticies are typically labelled $0$ through $n-1$ for convenience (recall that arrays and lists in most languages begin at index 0). This allows us to represent an adjacency list using a list of lists that store ints. Given an edge list, the following code will create an adjacency list for an **unweighted directed graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adj_list(n, edge_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        n:int = number of nodes in the graph. The nodes are labelled with integers 0 through n-1\n",
    "        edge_list:List[Tuple(int,int)] = edge list where each tuple (u,v) represents the directed \n",
    "            edge (u,v) in the graph\n",
    "    return:\n",
    "        A List[List[int]] representing the adjacency list \n",
    "    \"\"\"\n",
    "    adj_list = [[] for i in range(n)] \n",
    "    for u, v in edge_list:\n",
    "        adj_list[u].append(v)\n",
    "    for nodes in adj_list:\n",
    "        nodes.sort()\n",
    "    return adj_list\n",
    "\n",
    "def draw_graph(adj_list):\n",
    "    \"\"\"Utility method for visualizing graphs\n",
    "\n",
    "    args:\n",
    "        adj_list (List[List[int]]): adjacency list of the graph given by generate_adj_list\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for u in range(len(adj_list)):\n",
    "        for v in adj_list[u]:\n",
    "            G.add_edge(u, v)\n",
    "    nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1) Reconstructing the DFS Path\n",
    "\n",
    "In class we showed how to use DFS to check if there exists a path between two nodes, topologically sort nodes, and find SCCs. In those algorithms, pre and post numbers were used.\n",
    "\n",
    "Here you'll implement a variation of DFS to print out the path between two nodes. In many problems, we want to be able to find the actual path between two nodes, not just determine if it exists. \n",
    "\n",
    "> **Task:** Compute a path from $s$ to $t$ using DFS and return the path as a list of nodes on that path. \n",
    "\n",
    "For example, the path ${s \\to a \\to b \\to c \\to t}$ corresponds to the list `[s, a, b, c, t]`. If no path exists, return the empty list `[]`.\n",
    "\n",
    "You do not need to implement calculating pre and post numbers for this exercise.\n",
    "\n",
    "*Hint:*\n",
    "1. If you want to start with the recursive DFS implementation from DPV, you can use [mutable types or the `nonlocal` keyword](https://cs61a.org/study-guide/mutation/#local-state) to preserve state across recursive calls.\n",
    "2. It may be helpful to maintain an extra data structure which tracks the previous node we visited each time we visit a new node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dfs_path(adj_list, s, t):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List] = an adjacency list \n",
    "        s:int = an int representing the starting node\n",
    "        t:int = an int representing the destination node\n",
    "\n",
    "    return: \n",
    "        a list of nodes starting with s and ending with t representing an s to t path if it exists. \n",
    "        Returns an empty list otherwise\n",
    "    \"\"\"\n",
    "    def explore(adj_list, curr):\n",
    "        \"\"\"\n",
    "        implements the explore subroutine from DPV, which is used in DFS. feel free to delete this \n",
    "        function and use an alternative implementation if you prefer.\n",
    "\n",
    "        args:\n",
    "            adj_list:List[List] = an adjacency list \n",
    "            curr:int = the node currently being traversed\n",
    "        \n",
    "        return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    # implement the dfs and path reconstruction here\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "You can create sample tests in the following cells to help debug your solution. We provide a few small tests as an example, but they might not be comprehensive.\n",
    "\n",
    "To add a new graph to the test, append a new edge list to `edge_lists` as shown in the next cell.  \n",
    "__Remember that these edges are directed, so do not add both directions of an edge to the edge list.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lists = []\n",
    "edge_lists.append([(0,1), (0,2), (1,2), (2,3), (3,4), (3,5), (4,5)])   # edge list of first graph\n",
    "edge_lists.append([(0,1), (0,2), (1,2), (3,4), (3,5), (4,5)])          # edge list of second graph\n",
    "# add any additional tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each test case you also need to add a starting node $s$, a destination node $t$, and $n$ the number of nodes in the graph, add them to the following lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = []\n",
    "s_list.append(0)  # s for first graph \n",
    "s_list.append(1)  # s for second graph \n",
    "# add any additional tests here\n",
    "\n",
    "t_list = []\n",
    "t_list.append(3)  # t for first graph\n",
    "t_list.append(4)  # t for second graph\n",
    "# add any additional tests here\n",
    "\n",
    "n_list = []\n",
    "n_list.append(6)  # n = 6 for first graph\n",
    "n_list.append(6)  # n = 6 for second graph\n",
    "# add any additional tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a simplified version of the autograder, you may want to add more print statements or other debugging statements to check your function.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = 1\n",
    "for s, t, n, edge_list in zip(s_list, t_list, n_list, edge_lists):\n",
    "    print(\"Testing graph:\", index)\n",
    "    index += 1\n",
    "    \n",
    "    adj_list_graph = generate_adj_list(n, edge_list) # function defined earlier\n",
    "    \n",
    "    path = dfs_path(adj_list_graph, s, t) \n",
    "    \n",
    "    nx_graph = nx.DiGraph(edge_list)\n",
    "    \n",
    "    # uncomment the following to plot each graph\n",
    "    '''\n",
    "    nx.draw(nx_graph, with_labels=True)\n",
    "    plt.title(f\"Graph with {n} vertices and start node {s} and destination {t}\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    if not nx.has_path(nx_graph,s,t):\n",
    "        assert len(path) == 0, f\"your dfs_path found an s-t path when there isn't one.\"\n",
    "    else:\n",
    "        # checks that the path returned is a real path in the graph and that it starts and ends \n",
    "        # at the right vertices\n",
    "        assert nx.is_simple_path(nx_graph, path), f\"your dfs_path did not return a valid simple path\"\n",
    "        assert path[0] == s, f\"your dfs_path returned a valid simple path, but it does not start at node s\"\n",
    "        assert path[-1] == t, f\"your dfs_path returned a valid simple path, but it does not end at node t\"\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Pre and Post Numbers\n",
    "In order to topologically sort or find strongly connected components, we need to be able to calculate pre and post numbers for each node. \n",
    "\n",
    "In this part, you will rework your implementation of DFS to allow it to generate pre and post order numbers for each node. It might be a good idea to copy/paste your solution from the previous part and modify it here. \n",
    "\n",
    "> **Task:** Implement a function that computes DFS pre and post numbers for each node in the graph.\n",
    "\n",
    "To pass the autograder, your smallest preorder number should be 1. Your largest postorder number should be  $ 2 \\times \\text{(number of vertices)}$. Return two lists of tuples, a `pre` list should containing tuples `(node, pre-number)`, and a `post` list containing tuples `(node, post-number)`. \n",
    "\n",
    "Both lists should be ordered according to the pre/post number in the tuple. **You should not use any sorting functions to accomplish this!**\n",
    "\n",
    "> **Reflect:** Why might returning pre/post numbers in this way be helpful for finding strongly connected components?\n",
    "\n",
    "Feel free to delete the starter code and implement your own solution.\n",
    "\n",
    "For this part, you can no longer assume that the entire graph is guaranteed to be reachable from some certain start node. How will this change your implementation?\n",
    "\n",
    "Finally, break ties by choosing the node with the smallest number value. The autograder may fail implementations which are otherwise correct but break ties in a different way.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pre_post(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List[Tuple(int, int)], List[Tuple(int, int)] representing the pre and post order values\n",
    "            respectively. Each tuple should have a vertex as its first entry, and the pre/post order\n",
    "            value as its second entry.\n",
    "    \"\"\"\n",
    "    time = 1\n",
    "    pre = []\n",
    "    post = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "            \n",
    "    return pre, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) Strongly Connected Components (Kosaraju-Sharir Algorithm)\n",
    "\n",
    "We will now see how we can tie the concepts of DFS traversals and pre/post order values to obtain the strongly conencted components within a graph. SCC meta graphs are useful in that they allow us to construct DAGs, linearize a graph that contains cycles and obtain equivalence classes within a graph among other use cases.\n",
    "\n",
    "S. Rao Kosaraju and Micha Sharir independently solved this problem of finding the SCCs within a graph with the Kosaraju-Sharir Algorithm (which is the algorithm presented in the DPV notes section 3.4.2). \n",
    "\n",
    "A high-level overview of the algorithm is as follows:\n",
    "1. Run DFS on the reversed graph and store the post numbers of each node.\n",
    "2. Run DFS on the original graph, visiting nodes in decreasing post number order. Each DFS tree in this traversal is an SCC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is a reversed graph $G^R$. In this part, we'll implement a function to reverse a graph represented as an adjacency list.\n",
    "\n",
    "> **Task:** Given a graph represented as an adjacency list, return the acjacency list that represents the reversed graph (the vertex set is the same as the input graph, the edge set contains $(v, u)$ if and only if $(u, v)$ is present in the input graph's edge set).\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_graph(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List[List[int]] representing the adjacency list of the reversed input graph\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you get to complete the rest of the algorithm to find the SCCs within a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task:**\n",
    ">* Given a graph represented as an adjacency list, return a list of SCC components. Return SCCs in the order that they are found.\n",
    ">* The SCC components should be represented as Python `Set`s that contain only the nodes present in that SCC.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_SCCs(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List(Set(int, ...), ...) a list of sets where each set contains all the nodes \n",
    "            that belong to the corresponding SCC\n",
    "    \"\"\"\n",
    "    scc_list = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "    return scc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs170-fa23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "otter": {
   "OK_FORMAT": false,
   "assignment_name": "dfs-scc",
   "tests": {
    "q1.1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1.1\"\npoints = 2.0\n\n@test_case(points=None, hidden=False)\ndef test_q1_1(dfs_path, nx, tqdm, np, generate_adj_list, rng_seed):\n    rng = np.random.default_rng(rng_seed)\n\n    import signal\n    def timeout_handler(num, stack):\n        raise Exception(\"Your solution timed out.\")\n    if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n        signal.signal(signal.SIGALRM, timeout_handler)\n        signal.alarm(30)\n    \n    try:\n        for n in tqdm.tqdm(range(20,1001,20)):\n            # nice value to ensure graph is probably connected but\n            # big graphs are not too dense (slow)\n            p = np.log(n) / n\n            random_graph = nx.gnp_random_graph(n, p, seed=rng_seed+n, directed=True)\n\n            # note that the graph (and the adjacency list) is directed\n            adj_list_graph = generate_adj_list(n, random_graph.edges)\n            # TODO: delete old code\n            # adj_list_graph = [[] for i in range(n)]\n            # for u, line in zip(range(n),nx.generate_adjlist(random_graph)): \n            #     for v in line.split():\n            #         if int(v) != int(u):\n            #             adj_list_graph[int(v)].append(int(u))\n\n            s = rng.integers(n)\n            t = rng.integers(n)\n\n            # bans networkx\n            nxall = nx\n            def error(*args, **kwargs):\n                nx = nxall\n                raise Exception(\"You may not call any graph libraries, modules, or functions.\")\n            nx = error\n\n            try:\n                path = dfs_path(adj_list_graph, s, t)\n            finally: \n                nx = nxall \n\n            if not nx.has_path(random_graph,s,t):\n                assert len(path) == 0, f\"your dfs_path found an s-t path when there isn't one.\"\n            else:\n                # checks that the path returned is a real path in the graph and that it starts and ends \n                # at the right vertices\n                assert nx.is_simple_path(random_graph, path), f\"your dfs_path did not return a valid simple path\"\n                assert path[0] == s, f\"your dfs_path returned a valid simple path, but it does not start at node s\"\n                assert path[-1] == t, f\"your dfs_path returned a valid simple path, but it does not end at node t\"\n    finally:\n        if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n            signal.alarm(0)\n",
    "q1.2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1.2\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q1_2(get_pre_post, inputs, outputs, tqdm, nx, np, generate_adj_list, rng_seed):\n    import signal\n    def timeout_handler(num, stack):\n        raise Exception(\"Your solution timed out.\")\n    if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n        signal.signal(signal.SIGALRM, timeout_handler)\n        signal.alarm(30)\n    \n    try:\n        for i in tqdm.tqdm(range(len(inputs['q2']))):\n            input_adjlist = inputs['q2'][i]\n            n = len(input_adjlist)\n\n            # bans networkx\n            nxall = nx\n            def error(*args, **kwargs):\n                nx = nxall\n                raise Exception(\"You may not call any graph libraries, modules, or functions.\")\n            nx = error\n\n            try:\n                preStudent, postStudent = get_pre_post(input_adjlist)\n            finally: \n                nx = nxall \n\n            assert len(preStudent) == len(postStudent) == n, \"pre and post arrays should both have length n\"\n\n            # ensure pre and post are ordered correctly\n            for j in range(n-1):\n                assert preStudent[j][1] < preStudent[j+1][1], \"pre order values should be in increasing order\"\n                assert postStudent[j][1] < postStudent[j+1][1], \"post order values should be in increasing order\"\n\n            # ensure that the pre and post arrays are correct\n            expectedPre, expectedPost = outputs['q2'][i]\n            assert len(expectedPre) == len(preStudent) and len(expectedPost) == len(postStudent), 'make sure to set pre and post for each node'\n            for j in range(len(expectedPre)):\n                assert len(preStudent[j]) == 2, 'Make sure each value is (node, pre/post order)'\n                assert preStudent[j] == expectedPre[j], f'wrong preorder value for node {preStudent[j][0]}'\n            for j in range(len(expectedPost)):\n                assert len(postStudent[j]) == 2, 'Make sure each value is (node, pre/post order)'\n                assert postStudent[j] == expectedPost[j], f'wrong preorder value for node {postStudent[j][0]}'\n    \n    finally:\n        if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n            signal.alarm(0)\n\n",
    "q2.1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.1\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q2_1(reverse_graph, inputs, outputs, tqdm):\n    for i in tqdm.tqdm(range(len(inputs['q3']))):\n        reversed_graph = reverse_graph(inputs['q3'][i])\n        assert reversed_graph == outputs['q3'][i], 'wrong adjacency list returned for the reversed graph'\n\n",
    "q2.2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.2\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q2_2(find_SCCs, nx, inputs, outputs, tqdm):\n    import signal\n    def timeout_handler(num, stack):\n        raise Exception(\"Your solution timed out.\")\n    if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n        signal.signal(signal.SIGALRM, timeout_handler)\n        signal.alarm(45)\n    try:\n        # bans networkx\n        nxall = nx\n        def error(*args, **kwargs):\n            nx = nxall\n            raise Exception(\"You may not call any graph libraries, modules, or functions.\")\n        nx = error\n\n        try:\n            for i in tqdm.tqdm(range(len(inputs['q4']))):\n                scc_list = find_SCCs(inputs['q4'][i])\n                scc_sets = {frozenset(c) for c in scc_list}\n                assert scc_sets == outputs['q4'][i], 'wrong SCCs found'\n        finally:\n            nx = nxall\n\n    finally:\n        if hasattr(signal, 'SIGALRM') and hasattr(signal, 'alarm'):\n            signal.alarm(0)\n\n"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
